import pandas as pd
import io
import json
import streamlit as st
from src.models.models import JsonStructureDB
import os
import logging
from datetime import datetime

def get_by_path(data, path):
    """æŒ‰è·¯å¾„æå–åµŒå¥—å­—æ®µï¼Œæ”¯æŒ data.items è¿™ç§ç‚¹å·åˆ†éš”ï¼Œä¹Ÿæ”¯æŒæ•°ç»„ç´¢å¼•"""
    if not path:
        return data
    
    keys = path.split('.')
    current = data
    
    for key in keys:
        if current is None:
            return None
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°ç»„ç´¢å¼•
        if '[' in key and ']' in key:
            # å¤„ç†æ•°ç»„ç´¢å¼•ï¼Œå¦‚ records[0]
            array_name = key.split('[')[0]
            index_str = key.split('[')[1].split(']')[0]
            
            if isinstance(current, dict):
                current = current.get(array_name, None)
            else:
                return None
            
            if current is None:
                return None
            
            try:
                index = int(index_str)
                if isinstance(current, list) and 0 <= index < len(current):
                    current = current[index]
                else:
                    return None
            except (ValueError, TypeError):
                return None
        else:
            # æ™®é€šå­—æ®µè®¿é—®
            if isinstance(current, dict):
                current = current.get(key, None)
            else:
                return None
    
    return current

def parse_multi_json(text):
    """
    æ”¯æŒå¤šç§æ ¼å¼ï¼š
    1. å•ä¸ªJSONå¯¹è±¡æˆ–æ•°ç»„
    2. å¤šè¡Œï¼Œæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
    3. ç”¨ --- åˆ†å‰²çš„å¤šä¸ªJSONå¯¹è±¡
    """
    text = text.strip()
    # 1. å°è¯•æ ‡å‡†JSON
    try:
        return json.loads(text)
    except Exception:
        pass
    # 2. å°è¯•æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
    lines = [line for line in text.splitlines() if line.strip()]
    objs = []
    for line in lines:
        try:
            obj = json.loads(line)
            objs.append(obj)
        except Exception:
            break
    if len(objs) == len(lines) and objs:
        return objs
    # 3. å°è¯•ç”¨ --- åˆ†å‰²
    blocks = [b for b in text.split('---') if b.strip()]
    objs = []
    for block in blocks:
        try:
            obj = json.loads(block)
            objs.append(obj)
        except Exception:
            break
    if len(objs) == len(blocks) and objs:
        return objs
    raise ValueError('æ— æ³•è¯†åˆ«çš„JSONæ ¼å¼ï¼Œè¯·æ£€æŸ¥è¾“å…¥ï¼')

def json_to_excel(json_data, file_name='data.xlsx', list_path=None):
    """
    :param list_path: str, å¦‚ 'data' æˆ– 'data.items'ï¼ŒæŒ‡å®šå¯¼å‡ºä¸ºè¡¨æ ¼çš„å­—æ®µè·¯å¾„
    :return: bytes, Excelæ–‡ä»¶å†…å®¹
    """
    import pandas as pd
    import io
    if list_path:
        # å¦‚æœ json_data æ˜¯ listï¼Œåˆ™å¯¹æ¯ä¸ªå…ƒç´ æå–è·¯å¾„å¹¶åˆå¹¶
        if isinstance(json_data, list):
            all_rows = []
            for item in json_data:
                target = get_by_path(item, list_path)
                if isinstance(target, list):
                    all_rows.extend(target)
                elif target is not None:
                    all_rows.append(target)
            if not all_rows:
                raise ValueError('æŒ‡å®šè·¯å¾„æœªæ‰¾åˆ° list æ•°æ®')
            df = pd.DataFrame(all_rows)
        else:
            target = get_by_path(json_data, list_path)
            if isinstance(target, list):
                df = pd.DataFrame(target)
            else:
                raise ValueError('æŒ‡å®šè·¯å¾„æœªæ‰¾åˆ° list æ•°æ®')
    else:
        # å…¼å®¹åŸæœ‰è‡ªåŠ¨æ¨æ–­
        if isinstance(json_data, dict):
            for v in json_data.values():
                if isinstance(v, list):
                    df = pd.DataFrame(v)
                    break
            else:
                df = pd.DataFrame([json_data])
        elif isinstance(json_data, list):
            df = pd.DataFrame(json_data)
        else:
            raise ValueError('æ— æ³•è¯†åˆ«çš„ json æ•°æ®ç»“æ„')
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name="æ•°æ®")
    output.seek(0)
    return output.getvalue()

def json_to_excel_demo():
    st.title("JSONè½¬Excelå·¥å…·æ¼”ç¤º")
    st.write("ç²˜è´´ä½ çš„JSONæ•°æ®ï¼Œç‚¹å‡»æŒ‰é’®å³å¯ä¸‹è½½Excelæ–‡ä»¶")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    try:
        db = JsonStructureDB()
        has_db = True
    except:
        has_db = False
        st.warning("âš ï¸ æ•°æ®åº“åŠŸèƒ½ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€åŠŸèƒ½")
    
    example_json = '{\n  "data": [\n    {"name": "å¼ ä¸‰", "age": 18, "score": 90},\n    {"name": "æå››", "age": 20, "score": 85}\n  ]\n}'
    
    if st.button("æ’å…¥å‚è€ƒJSONæ¨¡æ¿"):
        st.session_state["json_demo_text"] = example_json
    
    json_str = st.text_area("ç²˜è´´JSONæ•°æ®", height=200, key="json_demo_text", value=st.session_state.get("json_demo_text", ""))
    
    # è‡ªåŠ¨æ£€æµ‹åŠŸèƒ½
    detected_path = None
    if has_db and json_str.strip():
        try:
            json_data = parse_multi_json(json_str)
            if isinstance(json_data, dict):
                detected_path = db.auto_detect_structure(json_data)
                if detected_path:
                    st.success(f"ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°ç»“æ„: `{detected_path}`")
        except:
            pass
    
    # è·¯å¾„é€‰æ‹©
    col1, col2 = st.columns([2, 1])
    
    with col1:
        list_path = st.text_input(
            "è¦å¯¼å‡ºçš„å­—æ®µè·¯å¾„ï¼ˆå¦‚ data æˆ– data.itemsï¼Œå¯ç•™ç©ºè‡ªåŠ¨æ¨æ–­ï¼‰", 
            value=detected_path or st.session_state.get("json_demo_path", "data")
        )
    
    with col2:
        if has_db:
            # æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„ç»“æ„é€‰é¡¹
            active_structures = db.get_all_active()
            if active_structures:
                st.write("**ğŸ—„ï¸ æ•°æ®åº“ç»“æ„:**")
                for structure in active_structures[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    if st.button(f"{structure.name}", key=f"demo_{structure.id}"):
                        st.session_state["json_demo_path"] = structure.path_pattern
                        st.rerun()
    
    # è·¯å¾„é€‰é¡¹ï¼ˆä»æ•°æ®åº“è·å–ï¼‰
    if has_db:
        st.write("**ğŸ“‹ æ•°æ®åº“ä¸­çš„ç»“æ„é€‰é¡¹:**")
        active_structures = db.get_all_active()
        if active_structures:
            cols = st.columns(3)
            for i, structure in enumerate(active_structures):
                if cols[i % 3].button(f"ğŸ“‹ {structure.name}", key=f"demo_path_{i}"):
                    st.session_state["json_demo_path"] = structure.path_pattern
                    st.rerun()
        else:
            st.info("æ•°æ®åº“ä¸­æ²¡æœ‰æ¿€æ´»çš„ç»“æ„ï¼Œè¯·åœ¨'JSONç»“æ„ç®¡ç†'ä¸­æ·»åŠ ")
    
    if st.button("ç”ŸæˆExcel"):
        try:
            json_data = parse_multi_json(json_str)
            if json_data is not None:
                excel_bytes = json_to_excel(json_data, list_path=list_path.strip() or None)
                st.download_button("ä¸‹è½½ Excel", data=excel_bytes, file_name="data.xlsx")
                
                # æ˜¾ç¤ºå¯¼å‡ºä¿¡æ¯
                st.success("âœ… Excelæ–‡ä»¶ç”ŸæˆæˆåŠŸï¼")
                if list_path.strip():
                    st.info(f"ğŸ“Š å¯¼å‡ºè·¯å¾„: `{list_path}`")
                
                # æ˜¾ç¤ºæ•°æ®ç»“æ„ä¿¡æ¯
                if isinstance(json_data, dict):
                    st.write("**ğŸ“‹ æ•°æ®ç»“æ„åˆ†æ:**")
                    def analyze_structure(obj, prefix="", max_depth=2, current_depth=0):
                        if current_depth >= max_depth:
                            return f"{prefix}... (æ·±åº¦é™åˆ¶)"
                        if isinstance(obj, dict):
                            result = []
                            for k, v in obj.items():
                                if isinstance(v, (dict, list)):
                                    result.append(f"{prefix}{k}: {type(v).__name__}")
                                    if current_depth < max_depth - 1:
                                        result.append(analyze_structure(v, prefix + "  ", max_depth, current_depth + 1))
                                else:
                                    result.append(f"{prefix}{k}: {type(v).__name__} = {str(v)[:30]}")
                            return "\n".join(result)
                        elif isinstance(obj, list):
                            if len(obj) > 0:
                                return f"{prefix}list[{len(obj)}] - ç¬¬ä¸€ä¸ªå…ƒç´ : {analyze_structure(obj[0], prefix + '  ', max_depth, current_depth + 1)}"
                            else:
                                return f"{prefix}list[0]"
                        else:
                            return f"{prefix}{type(obj).__name__}"
                    
                    structure_info = analyze_structure(json_data)
                    st.code(structure_info, language="text")
            else:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„JSONæ•°æ®")
        except Exception as e:
            st.error(f"è§£ææˆ–å¯¼å‡ºå¤±è´¥: {e}")
            st.write("**ğŸ’¡ è°ƒè¯•å»ºè®®:**")
            st.write("1. æ£€æŸ¥JSONæ ¼å¼æ˜¯å¦æ­£ç¡®")
            st.write("2. ç¡®è®¤å¯¼å‡ºè·¯å¾„æ˜¯å¦å­˜åœ¨")
            st.write("3. å°è¯•ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹çš„è·¯å¾„")
            if has_db:
                st.write("4. åœ¨'JSONç»“æ„ç®¡ç†'ä¸­æ·»åŠ æ–°çš„ç»“æ„æ¨¡å¼") 

class Logger:
    """ç®€å•æ—¥å¿—å·¥å…·ï¼ŒæŒ‰å¤©åˆ†æ–‡ä»¶ï¼Œå†™å…¥data/logs/ç›®å½•"""
    def __init__(self, log_dir='data/logs'):
        self.log_dir = log_dir
        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)
        self.logger = None
        self.current_date = None
        self._update_logger()

    def _update_logger(self):
        today = datetime.now().strftime('%Y%m%d')
        if self.current_date != today:
            self.current_date = today
            log_file = os.path.join(self.log_dir, f'{today}.log')
            self.logger = logging.getLogger(f'xzx_{today}')
            # è®¾ç½®ä¸ºDEBUGçº§åˆ«
            self.logger.setLevel(logging.DEBUG)
            # é¿å…é‡å¤æ·»åŠ handler
            if not self.logger.handlers:
                fh = logging.FileHandler(log_file, encoding='utf-8')
                # æ–‡ä»¶handlerä¹Ÿè®¾ç½®ä¸ºDEBUGçº§åˆ«
                fh.setLevel(logging.DEBUG)
                formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
                fh.setFormatter(formatter)
                self.logger.addHandler(fh)
                # ç¦ç”¨æ§åˆ¶å°è¾“å‡º
                self.logger.propagate = False

    def log(self, msg, level='info'):
        self._update_logger()
        if level == 'debug':
            self.logger.debug(msg)
        elif level == 'info':
            self.logger.info(msg)
        elif level == 'warn':
            self.logger.warning(msg)
        elif level == 'error':
            self.logger.error(msg)
        else:
            self.logger.info(msg) 